{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Experimentation on RF model training for integration with Flask Application</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load datasets\n",
    "ceas = 'data/CEAS_08.csv'\n",
    "nazario = 'data/Nazario.csv'\n",
    "fraud = 'data/Nigerian_Fraud.csv'\n",
    "spam = 'data/SpamAssasin.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ceas = pd.read_csv('data/CEAS_08.csv')\n",
    "nazario = pd.read_csv('data/Nazario.csv')\n",
    "fraud = pd.read_csv('data/Nigerian_Fraud.csv')\n",
    "spam = pd.read_csv('data/SpamAssasin.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              sender  \\\n",
      "0                   Young Esposito <Young@iworld.de>   \n",
      "1                       Mok <ipline's1983@icable.ph>   \n",
      "2  Daily Top 10 <Karmandeep-opengevl@universalnet...   \n",
      "3                 Michael Parker <ivqrnai@pobox.com>   \n",
      "4  Gretchen Suggs <externalsep1@loanofficertool.com>   \n",
      "\n",
      "                                         receiver  \\\n",
      "0                     user4@gvc.ceas-challenge.cc   \n",
      "1                   user2.2@gvc.ceas-challenge.cc   \n",
      "2                   user2.9@gvc.ceas-challenge.cc   \n",
      "3  SpamAssassin Dev <xrh@spamassassin.apache.org>   \n",
      "4                   user2.2@gvc.ceas-challenge.cc   \n",
      "\n",
      "                              date  \\\n",
      "0  Tue, 05 Aug 2008 16:31:02 -0700   \n",
      "1  Tue, 05 Aug 2008 18:31:03 -0500   \n",
      "2  Tue, 05 Aug 2008 20:28:00 -1200   \n",
      "3  Tue, 05 Aug 2008 17:31:20 -0600   \n",
      "4  Tue, 05 Aug 2008 19:31:21 -0400   \n",
      "\n",
      "                                             subject  \\\n",
      "0                          Never agree to be a loser   \n",
      "1                             Befriend Jenna Jameson   \n",
      "2                               CNN.com Daily Top 10   \n",
      "3  Re: svn commit: r619753 - in /spamassassin/tru...   \n",
      "4                         SpecialPricesPharmMoreinfo   \n",
      "\n",
      "                                                body  label  urls  \n",
      "0  Buck up, your troubles caused by small dimensi...      1     1  \n",
      "1  \\nUpgrade your sex and pleasures with these te...      1     1  \n",
      "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...      1     1  \n",
      "3  Would anyone object to removing .so from this ...      0     1  \n",
      "4  \\nWelcomeFastShippingCustomerSupport\\nhttp://7...      1     1  \n",
      "                                              sender  \\\n",
      "0  Mail System Internal Data <MAILER-DAEMON@monke...   \n",
      "1                        cPanel <service@cpanel.com>   \n",
      "2    Microsoft Outlook <recepcao@unimedceara.com.br>   \n",
      "3                     Ann Garcia <AnGarcia@mcoe.org>   \n",
      "4                 \"USAA\" <usaaacctupdate@sccu4u.com>   \n",
      "\n",
      "                                 receiver  \\\n",
      "0                                     NaN   \n",
      "1                         jose@monkey.org   \n",
      "2                                     NaN   \n",
      "3     \"info@maaaaa.org\" <info@maaaaa.org>   \n",
      "4  Recipients <usaaacctupdate@sccu4u.com>   \n",
      "\n",
      "                                    date  \\\n",
      "0             28 Sep 2017 09:57:25 -0400   \n",
      "1        Fri, 30 Oct 2015 00:00:48 -0500   \n",
      "2  Fri, 30 Oct 2015 06:21:59 -0300 (BRT)   \n",
      "3        Fri, 30 Oct 2015 14:54:33 +0000   \n",
      "4        Fri, 30 Oct 2015 14:02:33 -0500   \n",
      "\n",
      "                                             subject  \\\n",
      "0  DON'T DELETE THIS MESSAGE -- FOLDER INTERNAL DATA   \n",
      "1                                Verify Your Account   \n",
      "2                          Helpdesk Mailbox Alert!!!   \n",
      "3                               IT-Service Help Desk   \n",
      "4      Final USAA Reminder - Update Your Account Now   \n",
      "\n",
      "                                                body  urls  label  \n",
      "0  This text is part of the internal format of yo...     1      1  \n",
      "1  Business with  \\t\\t\\t\\t\\t\\t\\t\\tcPanel & WHM \\t...     1      1  \n",
      "2  Your two incoming mails were placed on pending...     1      1  \n",
      "3  Password will expire in 3 days. Click Here To ...     0      1  \n",
      "4  To ensure delivery to your inbox, please add U...     1      1  \n",
      "                                           sender              receiver  \\\n",
      "0  MR. JAMES NGOLA. <james_ngola2002@maktoob.com>  webmaster@aclweb.org   \n",
      "1  Mr. Ben Suleman <bensul2004nng@spinfinder.com>                   R@M   \n",
      "2       PRINCE OBONG ELEME <obong_715@epatra.com>  webmaster@aclweb.org   \n",
      "3       PRINCE OBONG ELEME <obong_715@epatra.com>  webmaster@aclweb.org   \n",
      "4              Maryam Abacha <m_abacha03@www.com>                   R@M   \n",
      "\n",
      "                              date  \\\n",
      "0  Thu, 31 Oct 2002 02:38:20 +0000   \n",
      "1  Thu, 31 Oct 2002 05:10:00 -0000   \n",
      "2  Thu, 31 Oct 2002 22:17:55 +0100   \n",
      "3  Thu, 31 Oct 2002 22:44:20 -0000   \n",
      "4  Fri, 01 Nov 2002 01:45:04 +0100   \n",
      "\n",
      "                                      subject  \\\n",
      "0  URGENT BUSINESS ASSISTANCE AND PARTNERSHIP   \n",
      "1         URGENT ASSISTANCE /RELATIONSHIP (P)   \n",
      "2                             GOOD DAY TO YOU   \n",
      "3                             GOOD DAY TO YOU   \n",
      "4                     I Need Your Assistance.   \n",
      "\n",
      "                                                body  urls  label  \n",
      "0  FROM:MR. JAMES NGOLA.\\nCONFIDENTIAL TEL: 233-2...     0      1  \n",
      "1  Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...     0      1  \n",
      "2  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...     0      1  \n",
      "3  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...     0      1  \n",
      "4  Dear sir, \\n \\nIt is with a heart full of hope...     0      1  \n",
      "                                      sender  \\\n",
      "0             Robert Elz <kre@munnari.OZ.AU>   \n",
      "1  Steve Burt <Steve_Burt@cursor-system.com>   \n",
      "2              \"Tim Chapman\" <timc@2ubh.com>   \n",
      "3           Monty Solomon <monty@roscom.com>   \n",
      "4  Stewart Smith <Stewart.Smith@ee.ed.ac.uk>   \n",
      "\n",
      "                                            receiver  \\\n",
      "0  Chris Garrigues <cwg-dated-1030377287.06fa6d@D...   \n",
      "1  \"'zzzzteana@yahoogroups.com'\" <zzzzteana@yahoo...   \n",
      "2              zzzzteana <zzzzteana@yahoogroups.com>   \n",
      "3                           undisclosed-recipient: ;   \n",
      "4                          zzzzteana@yahoogroups.com   \n",
      "\n",
      "                              date  \\\n",
      "0  Thu, 22 Aug 2002 18:26:25 +0700   \n",
      "1  Thu, 22 Aug 2002 12:46:18 +0100   \n",
      "2  Thu, 22 Aug 2002 13:52:38 +0100   \n",
      "3  Thu, 22 Aug 2002 09:15:25 -0400   \n",
      "4  Thu, 22 Aug 2002 14:38:22 +0100   \n",
      "\n",
      "                                          subject  \\\n",
      "0                        Re: New Sequences Window   \n",
      "1                       [zzzzteana] RE: Alexander   \n",
      "2                       [zzzzteana] Moscow bomber   \n",
      "3           [IRR] Klez: The Virus That  Won't Die   \n",
      "4  Re: [zzzzteana] Nothing like mama used to make   \n",
      "\n",
      "                                                body  label  urls  \n",
      "0  Date:        Wed, 21 Aug 2002 10:54:46 -0500  ...      0     1  \n",
      "1  Martin A posted:\\nTassos Papadopoulos, the Gre...      0     1  \n",
      "2  Man Threatens Explosion In Moscow \\n\\nThursday...      0     1  \n",
      "3  Klez: The Virus That Won't Die\\n \\nAlready the...      0     1  \n",
      "4  >  in adding cream to spaghetti carbonara, whi...      0     1  \n"
     ]
    }
   ],
   "source": [
    "print(ceas.head())\n",
    "print(nazario.head())\n",
    "print(fraud.head())\n",
    "print(spam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardise columns in all datasets\n",
    "ceas.columns = ['Sender', 'Receiver', 'Date', 'Subject', 'Body', 'Urls', 'Label']\n",
    "nazario.columns = ['Sender', 'Receiver', 'Date', 'Subject', 'Body', 'Urls', 'Label']\n",
    "fraud.columns = ['Sender', 'Receiver', 'Date', 'Subject', 'Body', 'Urls', 'Label']\n",
    "spam.columns = ['Sender', 'Receiver', 'Date', 'Subject', 'Body', 'Urls', 'Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine together the datasets for a larger sample\n",
    "combined_dataset = pd.concat([ceas, nazario, fraud, spam])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine dataset shape: (49860, 7)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Combine dataset shape: {combined_dataset.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Sender  \\\n",
      "0                    Young Esposito <Young@iworld.de>   \n",
      "1                        Mok <ipline's1983@icable.ph>   \n",
      "2   Daily Top 10 <Karmandeep-opengevl@universalnet...   \n",
      "3                  Michael Parker <ivqrnai@pobox.com>   \n",
      "4   Gretchen Suggs <externalsep1@loanofficertool.com>   \n",
      "5   Caroline Aragon <dwthaidomainnamesm@thaidomain...   \n",
      "6     Replica Watches <jhorton@thebakercompanies.com>   \n",
      "7              Daily Top 10 <acidirev_1972@tcwpg.com>   \n",
      "8                   qydlqcws-iacfym@issues.apache.org   \n",
      "9       Daily Top 10 <orn|dent_1973@musicaedischi.it>   \n",
      "10    ambrosius edwin <370jcmiller@flychautauqua.com>   \n",
      "11         Alejandra Levy <rehearsings46@gametea.com>   \n",
      "12      Daily Top 10 <Atchuthan-erbatest@weijgers.nl>   \n",
      "13  Daily Top 10 <Scooter-obailat@picklesmaternity...   \n",
      "14              Alphonso Roach <exited@realskate.com>   \n",
      "15                         Racing <uqyrmo@sailing.ie>   \n",
      "16  Daily Top 10 <Joep-ntorions@picklesmaternity.com>   \n",
      "17  Daily Top 10 <Marci-ntelstok@picklesmaternity....   \n",
      "18                Aaron Kulkis <cmiqlkx91@hotpop.com>   \n",
      "19                Aaron Kulkis <cmiqlkx91@hotpop.com>   \n",
      "\n",
      "                                          Receiver  \\\n",
      "0                      user4@gvc.ceas-challenge.cc   \n",
      "1                    user2.2@gvc.ceas-challenge.cc   \n",
      "2                    user2.9@gvc.ceas-challenge.cc   \n",
      "3   SpamAssassin Dev <xrh@spamassassin.apache.org>   \n",
      "4                    user2.2@gvc.ceas-challenge.cc   \n",
      "5                 user7-ext5@gvc.ceas-challenge.cc   \n",
      "6                   user2.10@gvc.ceas-challenge.cc   \n",
      "7                    user2.3@gvc.ceas-challenge.cc   \n",
      "8                      xrh@spamassassin.apache.org   \n",
      "9                      user7@gvc.ceas-challenge.cc   \n",
      "10                     user5@gvc.ceas-challenge.cc   \n",
      "11                  user2.13@gvc.ceas-challenge.cc   \n",
      "12              user8.2-ext1@gvc.ceas-challenge.cc   \n",
      "13                netsearche@gvc.ceas-challenge.cc   \n",
      "14                   user2.7@gvc.ceas-challenge.cc   \n",
      "15                     user5@gvc.ceas-challenge.cc   \n",
      "16                netsearchn@gvc.ceas-challenge.cc   \n",
      "17               netsearchnn@gvc.ceas-challenge.cc   \n",
      "18                opensuse <wkilxloc@opensuse.org>   \n",
      "19                opensuse <wkilxloc@opensuse.org>   \n",
      "\n",
      "                               Date  \\\n",
      "0   Tue, 05 Aug 2008 16:31:02 -0700   \n",
      "1   Tue, 05 Aug 2008 18:31:03 -0500   \n",
      "2   Tue, 05 Aug 2008 20:28:00 -1200   \n",
      "3   Tue, 05 Aug 2008 17:31:20 -0600   \n",
      "4   Tue, 05 Aug 2008 19:31:21 -0400   \n",
      "5   Wed, 06 Aug 2008 05:31:22 +0600   \n",
      "6   Tue, 05 Aug 2008 21:44:01 +0000   \n",
      "7   Tue, 05 Aug 2008 20:41:14 -0300   \n",
      "8   Tue, 05 Aug 2008 15:31:03 -0800   \n",
      "9   Wed, 06 Aug 2008 00:31:38 +0100   \n",
      "10  Tue, 05 Aug 2008 21:44:06 +0000   \n",
      "11  Tue, 05 Aug 2008 21:31:34 -0200   \n",
      "12  Wed, 06 Aug 2008 01:31:36 +0200   \n",
      "13  Tue, 05 Aug 2008 20:30:59 +0200   \n",
      "14  Tue, 05 Aug 2008 18:31:39 -0500   \n",
      "15  Wed, 06 Aug 2008 00:31:14 +0100   \n",
      "16  Tue, 05 Aug 2008 20:31:12 +0200   \n",
      "17  Tue, 05 Aug 2008 20:31:16 +0200   \n",
      "18  Tue, 05 Aug 2008 15:50:37 -0500   \n",
      "19  Tue, 05 Aug 2008 16:31:41 -0500   \n",
      "\n",
      "                                              Subject  \\\n",
      "0                           Never agree to be a loser   \n",
      "1                              Befriend Jenna Jameson   \n",
      "2                                CNN.com Daily Top 10   \n",
      "3   Re: svn commit: r619753 - in /spamassassin/tru...   \n",
      "4                          SpecialPricesPharmMoreinfo   \n",
      "5                                From Caroline Aragon   \n",
      "6                                     Replica Watches   \n",
      "7                                CNN.com Daily Top 10   \n",
      "8   [Bug 5780] URI processing turns uuencoded stri...   \n",
      "9                                CNN.com Daily Top 10   \n",
      "10                                debt consolidation    \n",
      "11  It combines the best of Creative Suite 3 Desig...   \n",
      "12                               CNN.com Daily Top 10   \n",
      "13                               CNN.com Daily Top 10   \n",
      "14                                Fifth / Sixth month   \n",
      "15              RE: Trial IRC Certificate Application   \n",
      "16                               CNN.com Daily Top 10   \n",
      "17                               CNN.com Daily Top 10   \n",
      "18  Re: [opensuse] Why can't I use \"shutdown now\" ...   \n",
      "19    Re: Fwd: [opensuse] Re: openSUSE Boxed Editions   \n",
      "\n",
      "                                                 Body  Urls  Label  \n",
      "0   Buck up, your troubles caused by small dimensi...     1      1  \n",
      "1   \\nUpgrade your sex and pleasures with these te...     1      1  \n",
      "2   >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...     1      1  \n",
      "3   Would anyone object to removing .so from this ...     0      1  \n",
      "4   \\nWelcomeFastShippingCustomerSupport\\nhttp://7...     1      1  \n",
      "5   \\n\\n\\n\\n\\nYo wu urS mo ou go rc ebo eForM rgi ...     1      0  \n",
      "6   We have fake Swiss Men's and Ladie's Replica \\...     1      0  \n",
      "7   >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...     1      1  \n",
      "8   http://issues.apache.org/SpamAssassin/show_bug...     0      1  \n",
      "9   >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...     1      1  \n",
      "10  \\nDo Not consolidate your debt   Eliminate it!...     1      1  \n",
      "11  \\nAdobe Creative Suite 3 Master Collection for...     1      1  \n",
      "12  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...     1      1  \n",
      "13  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...     1      1  \n",
      "14  \\nexpressherbals\\n \\nhttp://pacelike.com\\n \\nF...     1      1  \n",
      "15  \\nPlelim,\\n\\nJust to remind you that if a cert...     0      1  \n",
      "16  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...     1      1  \n",
      "17  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...     1      1  \n",
      "18  Carlos E. R. wrote: > -----BEGIN PGP SIGNED ME...     0      1  \n",
      "19  Steve Jacobs wrote: > ---------- Forwarded mes...     0      1  \n"
     ]
    }
   ],
   "source": [
    "print(combined_dataset.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine dataset shape: (49772, 7)\n",
      "                                              Sender  \\\n",
      "0                   Young Esposito <Young@iworld.de>   \n",
      "1                       Mok <ipline's1983@icable.ph>   \n",
      "2  Daily Top 10 <Karmandeep-opengevl@universalnet...   \n",
      "3                 Michael Parker <ivqrnai@pobox.com>   \n",
      "4  Gretchen Suggs <externalsep1@loanofficertool.com>   \n",
      "\n",
      "                                         Receiver  \\\n",
      "0                     user4@gvc.ceas-challenge.cc   \n",
      "1                   user2.2@gvc.ceas-challenge.cc   \n",
      "2                   user2.9@gvc.ceas-challenge.cc   \n",
      "3  SpamAssassin Dev <xrh@spamassassin.apache.org>   \n",
      "4                   user2.2@gvc.ceas-challenge.cc   \n",
      "\n",
      "                              Date  \\\n",
      "0  Tue, 05 Aug 2008 16:31:02 -0700   \n",
      "1  Tue, 05 Aug 2008 18:31:03 -0500   \n",
      "2  Tue, 05 Aug 2008 20:28:00 -1200   \n",
      "3  Tue, 05 Aug 2008 17:31:20 -0600   \n",
      "4  Tue, 05 Aug 2008 19:31:21 -0400   \n",
      "\n",
      "                                             Subject  \\\n",
      "0                          Never agree to be a loser   \n",
      "1                             Befriend Jenna Jameson   \n",
      "2                               CNN.com Daily Top 10   \n",
      "3  Re: svn commit: r619753 - in /spamassassin/tru...   \n",
      "4                         SpecialPricesPharmMoreinfo   \n",
      "\n",
      "                                                Body  Urls  Label  \n",
      "0  Buck up, your troubles caused by small dimensi...     1      1  \n",
      "1  \\nUpgrade your sex and pleasures with these te...     1      1  \n",
      "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...     1      1  \n",
      "3  Would anyone object to removing .so from this ...     0      1  \n",
      "4  \\nWelcomeFastShippingCustomerSupport\\nhttp://7...     1      1  \n"
     ]
    }
   ],
   "source": [
    "#clean the data\n",
    "    #rem duplicates\n",
    "\n",
    "\n",
    "#rem dups\n",
    "combined_dataset = combined_dataset.drop_duplicates()\n",
    "\n",
    "#drop rows with missings vals\n",
    "combined_dataset = combined_dataset.dropna(subset=['Subject', 'Body'])\n",
    "\n",
    "#check shape \n",
    "print(f\"Combine dataset shape: {combined_dataset.shape}\")\n",
    "\n",
    "print(combined_dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Normalise labels</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in Label before any transformation: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"NaNs in Label before any transformation:\", combined_dataset['Label'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels [1 0]\n"
     ]
    }
   ],
   "source": [
    "#understand \n",
    "print(\"Original labels\", combined_dataset['Label'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "1    36073\n",
      "0    13699\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(combined_dataset['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset saved as 'Combined_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "combined_dataset.to_csv('data/combined_dataset.csv', index=False)\n",
    "\n",
    "print(\"Combined dataset saved as 'Combined_dataset.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Engineering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text processing \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (49772, 7)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset Shape: {combined_dataset.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>To lower, rem special char, nums, and weird punctuation, rem stopwords.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textstat import flesch_reading_ease, sentence_count\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#func to extract stylistic features\n",
    "def extract_text_features(text):\n",
    "    if pd.isnull(text):\n",
    "        return pd.Series([0, 0, 0, 0, 0, 0, 0]) # since is 7D feature vector.\n",
    "    \n",
    "    num_sentences = max(sentence_count(text), 1) #avoid div by 0\n",
    "    words = text.split() # split str to list\n",
    "    num_words = len(words)\n",
    "    num_chars = len(text)\n",
    "\n",
    "    #punctuation/capitalisation\n",
    "    punctuation_count = sum(1 for char in text if char in string.punctuation)\n",
    "    exclamation_count = text.count(\"!\")\n",
    "    question_count = text.count(\"?\")\n",
    "    uppercase_ration = sum(1 for char in text if char.isupper()) / max(len(text), 1)\n",
    "\n",
    "    #readability/sentence complexity\n",
    "    readability_score = flesch_reading_ease(text)\n",
    "    avg_word_length = num_chars / max(num_words, 1)\n",
    "    avg_sentence_length = num_words / num_sentences\n",
    "\n",
    "    return pd.Series([avg_sentence_length, avg_word_length, punctuation_count,\n",
    "                      exclamation_count, question_count, uppercase_ration, readability_score])  \n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sender</th>\n",
       "      <th>Receiver</th>\n",
       "      <th>Date</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Urls</th>\n",
       "      <th>Label</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>exclamation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>uppercase_ration</th>\n",
       "      <th>readability_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Young Esposito &lt;Young@iworld.de&gt;</td>\n",
       "      <td>user4@gvc.ceas-challenge.cc</td>\n",
       "      <td>Tue, 05 Aug 2008 16:31:02 -0700</td>\n",
       "      <td>Never agree to be a loser</td>\n",
       "      <td>Buck up, your troubles caused by small dimensi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>5.934783</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>87.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mok &lt;ipline's1983@icable.ph&gt;</td>\n",
       "      <td>user2.2@gvc.ceas-challenge.cc</td>\n",
       "      <td>Tue, 05 Aug 2008 18:31:03 -0500</td>\n",
       "      <td>Befriend Jenna Jameson</td>\n",
       "      <td>\\nUpgrade your sex and pleasures with these te...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.111111</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>45.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daily Top 10 &lt;Karmandeep-opengevl@universalnet...</td>\n",
       "      <td>user2.9@gvc.ceas-challenge.cc</td>\n",
       "      <td>Tue, 05 Aug 2008 20:28:00 -1200</td>\n",
       "      <td>CNN.com Daily Top 10</td>\n",
       "      <td>&gt;+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.743590</td>\n",
       "      <td>12.973510</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.164625</td>\n",
       "      <td>-3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael Parker &lt;ivqrnai@pobox.com&gt;</td>\n",
       "      <td>SpamAssassin Dev &lt;xrh@spamassassin.apache.org&gt;</td>\n",
       "      <td>Tue, 05 Aug 2008 17:31:20 -0600</td>\n",
       "      <td>Re: svn commit: r619753 - in /spamassassin/tru...</td>\n",
       "      <td>Would anyone object to removing .so from this ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49.259259</td>\n",
       "      <td>9.179699</td>\n",
       "      <td>5769.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.007535</td>\n",
       "      <td>-39.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gretchen Suggs &lt;externalsep1@loanofficertool.com&gt;</td>\n",
       "      <td>user2.2@gvc.ceas-challenge.cc</td>\n",
       "      <td>Tue, 05 Aug 2008 19:31:21 -0400</td>\n",
       "      <td>SpecialPricesPharmMoreinfo</td>\n",
       "      <td>\\nWelcomeFastShippingCustomerSupport\\nhttp://7...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205714</td>\n",
       "      <td>-1275.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sender  \\\n",
       "0                   Young Esposito <Young@iworld.de>   \n",
       "1                       Mok <ipline's1983@icable.ph>   \n",
       "2  Daily Top 10 <Karmandeep-opengevl@universalnet...   \n",
       "3                 Michael Parker <ivqrnai@pobox.com>   \n",
       "4  Gretchen Suggs <externalsep1@loanofficertool.com>   \n",
       "\n",
       "                                         Receiver  \\\n",
       "0                     user4@gvc.ceas-challenge.cc   \n",
       "1                   user2.2@gvc.ceas-challenge.cc   \n",
       "2                   user2.9@gvc.ceas-challenge.cc   \n",
       "3  SpamAssassin Dev <xrh@spamassassin.apache.org>   \n",
       "4                   user2.2@gvc.ceas-challenge.cc   \n",
       "\n",
       "                              Date  \\\n",
       "0  Tue, 05 Aug 2008 16:31:02 -0700   \n",
       "1  Tue, 05 Aug 2008 18:31:03 -0500   \n",
       "2  Tue, 05 Aug 2008 20:28:00 -1200   \n",
       "3  Tue, 05 Aug 2008 17:31:20 -0600   \n",
       "4  Tue, 05 Aug 2008 19:31:21 -0400   \n",
       "\n",
       "                                             Subject  \\\n",
       "0                          Never agree to be a loser   \n",
       "1                             Befriend Jenna Jameson   \n",
       "2                               CNN.com Daily Top 10   \n",
       "3  Re: svn commit: r619753 - in /spamassassin/tru...   \n",
       "4                         SpecialPricesPharmMoreinfo   \n",
       "\n",
       "                                                Body  Urls  Label  \\\n",
       "0  Buck up, your troubles caused by small dimensi...     1      1   \n",
       "1  \\nUpgrade your sex and pleasures with these te...     1      1   \n",
       "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...     1      1   \n",
       "3  Would anyone object to removing .so from this ...     0      1   \n",
       "4  \\nWelcomeFastShippingCustomerSupport\\nhttp://7...     1      1   \n",
       "\n",
       "   avg_sentence_length  avg_word_length  punctuation_count  exclamation_count  \\\n",
       "0             9.200000         5.934783               13.0                2.0   \n",
       "1             9.000000         9.111111                5.0                0.0   \n",
       "2             7.743590        12.973510              722.0                0.0   \n",
       "3            49.259259         9.179699             5769.0                4.0   \n",
       "4             2.000000        87.500000               13.0                0.0   \n",
       "\n",
       "   question_count  uppercase_ration  readability_score  \n",
       "0             0.0          0.021978              87.52  \n",
       "1             0.0          0.012195              45.42  \n",
       "2            15.0          0.164625              -3.42  \n",
       "3            75.0          0.007535             -39.39  \n",
       "4             0.0          0.205714           -1275.70  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply to dataset\n",
    "feature_names = ['avg_sentence_length', 'avg_word_length', 'punctuation_count',\n",
    "                 'exclamation_count', 'question_count', 'uppercase_ration', 'readability_score']\n",
    "\n",
    "combined_dataset[feature_names] = combined_dataset['Body'].apply(extract_text_features)\n",
    "combined_dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Detecting language anomalies</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#func to extract n-gram frequency patterns\n",
    "def extract_ngram_features(text, n=2):\n",
    "    if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "        return 0 \n",
    "    \n",
    "    vectorizer = CountVectorizer(ngram_range=(n, n), stop_words=None, lowercase=False)\n",
    "    \n",
    "    try:\n",
    "        X = vectorizer.fit_transform([text])\n",
    "        return np.sum(X.toarray())  #sum all n-grams\n",
    "    except ValueError:\n",
    "        return 0  # if vocab empty then return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the function\n",
    "combined_dataset['bigram_count'] = combined_dataset['Body'].apply(lambda x: extract_ngram_features(str(x), 2))\n",
    "combined_dataset['trigram_count'] = combined_dataset['Body'].apply(lambda x: extract_ngram_features(str(x), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>bigram_count</th>\n",
       "      <th>trigram_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buck up, your troubles caused by small dimensi...</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nUpgrade your sex and pleasures with these te...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&gt;+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...</td>\n",
       "      <td>589</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Would anyone object to removing .so from this ...</td>\n",
       "      <td>3816</td>\n",
       "      <td>3815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nWelcomeFastShippingCustomerSupport\\nhttp://7...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body  bigram_count  \\\n",
       "0  Buck up, your troubles caused by small dimensi...            45   \n",
       "1  \\nUpgrade your sex and pleasures with these te...            11   \n",
       "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...           589   \n",
       "3  Would anyone object to removing .so from this ...          3816   \n",
       "4  \\nWelcomeFastShippingCustomerSupport\\nhttp://7...            10   \n",
       "\n",
       "   trigram_count  \n",
       "0             44  \n",
       "1             10  \n",
       "2            588  \n",
       "3           3815  \n",
       "4              9  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify\n",
    "combined_dataset[['Body', 'bigram_count', 'trigram_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Extract sus URL features</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\raider\\AppData\\Local\\Temp\\ipykernel_19364\\4063913847.py:2: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  urls = re.findall(f'https?://\\S+|www\\.\\S+', text) #extract\n"
     ]
    }
   ],
   "source": [
    "def analyse_urls(text):\n",
    "    urls = re.findall(f'https?://\\S+|www\\.\\S+', text) #extract\n",
    "    num_urls = len(urls)\n",
    "    num_shortened_urls = sum(1 for u in urls if any(short in u for short in [\"bit.ly\", \"tinyurl\", \"goo.gl\"]))\n",
    "    avg_url_lngth = np.mean([len(u) for u in urls]) if urls else 0\n",
    "    return pd.Series([num_urls, num_shortened_urls, avg_url_lngth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset[['num_urls', 'num_shortened_urls', 'avg_url_lngth']] = combined_dataset['Body'].apply(analyse_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>num_urls</th>\n",
       "      <th>num_shortened_urls</th>\n",
       "      <th>avg_url_lngth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buck up, your troubles caused by small dimensi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nUpgrade your sex and pleasures with these te...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&gt;+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Would anyone object to removing .so from this ...</td>\n",
       "      <td>652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.995399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nWelcomeFastShippingCustomerSupport\\nhttp://7...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body  num_urls  \\\n",
       "0  Buck up, your troubles caused by small dimensi...       1.0   \n",
       "1  \\nUpgrade your sex and pleasures with these te...       1.0   \n",
       "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...      24.0   \n",
       "3  Would anyone object to removing .so from this ...     652.0   \n",
       "4  \\nWelcomeFastShippingCustomerSupport\\nhttp://7...       1.0   \n",
       "\n",
       "   num_shortened_urls  avg_url_lngth  \n",
       "0                 0.0      21.000000  \n",
       "1                 0.0      25.000000  \n",
       "2                 0.0      80.166667  \n",
       "3                 0.0      18.995399  \n",
       "4                 0.0     136.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check results\n",
    "combined_dataset[['Body', 'num_urls', 'num_shortened_urls', 'avg_url_lngth']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Analyse suspicious words</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "imperative_wrds = {'click', 'verify', 'update', 'login', 'download', 'pay', 'confirm', 'reset'}\n",
    "politeness_wrds = {'please', 'thank you', 'kindly', 'regards'}\n",
    "\n",
    "#func to check word usage\n",
    "def count_wrd_usge(text, word_list):\n",
    "    words = text.lower().split()\n",
    "    return sum(1 for w in words if w in word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply\n",
    "combined_dataset['imperative_word_count'] = combined_dataset['Body'].apply(lambda x: count_wrd_usge(str(x), imperative_wrds))\n",
    "combined_dataset['politeness_word_count'] = combined_dataset['Body'].apply(lambda x: count_wrd_usge(str(x), politeness_wrds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>imperative_word_count</th>\n",
       "      <th>politeness_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buck up, your troubles caused by small dimensi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nUpgrade your sex and pleasures with these te...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&gt;+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Would anyone object to removing .so from this ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nWelcomeFastShippingCustomerSupport\\nhttp://7...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body  imperative_word_count  \\\n",
       "0  Buck up, your troubles caused by small dimensi...                      0   \n",
       "1  \\nUpgrade your sex and pleasures with these te...                      0   \n",
       "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...                      0   \n",
       "3  Would anyone object to removing .so from this ...                      1   \n",
       "4  \\nWelcomeFastShippingCustomerSupport\\nhttp://7...                      0   \n",
       "\n",
       "   politeness_word_count  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      1  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "combined_dataset[['Body', 'imperative_word_count', 'politeness_word_count']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Extract special char frequency</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_spcl_chars(text):\n",
    "    if isinstance(text, str):\n",
    "        return len(re.findall(r'[!@#$%^&*()_+={}\\[\\]:;\"\\'<>,.?/~`]', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset['num_special_chars'] = combined_dataset['Body'].apply(count_spcl_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset updated with feature extraction\n"
     ]
    }
   ],
   "source": [
    "combined_dataset.to_csv('data/combined_dataset_with_features.csv', index=False)\n",
    "print(\"Dataset updated with feature extraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature set summary</h3>\n",
    "<p> \n",
    "*  avg_sentence_lngth --> Average num of words per sentence<br>\n",
    "*  avg_wrd_length     --> Average char count per word<br>\n",
    "*  punctuation_count  --> Total punctuation marks within email<br>\n",
    "*  exclamation_count  --> Number of '!' used<br>\n",
    "*  question_count     --> num of '?' used<br>\n",
    "*  uppercase_ration   --> % of char in upper<br>\n",
    "*  readability_score  --> ease of reading (lower = harder to read)<br>\n",
    "*  bigram_count       --> Frequency of common 2-word phrases<br>\n",
    "*  trigram_count      --> Frequency of common 3-word phrases<br>\n",
    "*  num_urls           --> Count of URLs in email<br> \n",
    "*  num_shortened_urls --> Count of shortened links (bit.ly, tinyurl etc)<br>\n",
    "*  avg_url_lngth      --> avrg URL length<br>\n",
    "*  imperative_word_count --> count of demanding action words<br>\n",
    "*  politeness_word_count --> count of politeness words<br><br>\n",
    "<h5>Linguistic Features: n-gram counts, punctuation frequency.</h5><br>\n",
    "<h5>Content features: URL presence, keyword frequency</h5><br>\n",
    "<h5>Metadata features: sender domain, email length</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Defining features and the labels</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load preprocess dataset\n",
    "df = pd.read_csv('data/combined_dataset_with_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define feature (independent vars)\n",
    "features = ['bigram_count', 'trigram_count', 'num_urls', 'avg_url_lngth']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sender', 'Receiver', 'Date', 'Subject', 'Body', 'Urls', 'Label',\n",
       "       'avg_sentence_length', 'avg_word_length', 'punctuation_count',\n",
       "       'exclamation_count', 'question_count', 'uppercase_ration',\n",
       "       'readability_score', 'bigram_count', 'trigram_count', 'num_urls',\n",
       "       'num_shortened_urls', 'avg_url_lngth', 'imperative_word_count',\n",
       "       'politeness_word_count', 'num_special_chars'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining target (dependent var)\n",
    "X = df[features]\n",
    "y = df['Label'] #Phishing 1 legit 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (39817, 4), Test set: (9955, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Train RF </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
